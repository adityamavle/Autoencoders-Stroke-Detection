{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "1gjXMfMsqw2P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/stroke.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO8mG_02DHJj",
        "outputId": "dd00fdbd-9ccd-45e6-fa60-ed3a5d7da408"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/stroke.zip\n",
            "replace healthcare-dataset-stroke-data.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/healthcare-dataset-stroke-data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "hEknyX2oFoUC",
        "outputId": "b832796b-0ec4-40cf-a7f2-6e1a93eef9a4"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
              "0   9046    Male  67.0             0              1          Yes   \n",
              "1  51676  Female  61.0             0              0          Yes   \n",
              "2  31112    Male  80.0             0              1          Yes   \n",
              "3  60182  Female  49.0             0              0          Yes   \n",
              "4   1665  Female  79.0             1              0          Yes   \n",
              "\n",
              "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
              "0        Private          Urban             228.69  36.6  formerly smoked   \n",
              "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
              "2        Private          Rural             105.92  32.5     never smoked   \n",
              "3        Private          Urban             171.23  34.4           smokes   \n",
              "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
              "\n",
              "   stroke  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e440dd88-19f9-41fb-ba6a-3b459542772c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9046</td>\n",
              "      <td>Male</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51676</td>\n",
              "      <td>Female</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>202.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31112</td>\n",
              "      <td>Male</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60182</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>smokes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1665</td>\n",
              "      <td>Female</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e440dd88-19f9-41fb-ba6a-3b459542772c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e440dd88-19f9-41fb-ba6a-3b459542772c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e440dd88-19f9-41fb-ba6a-3b459542772c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "JNPTS2NOGu_q",
        "outputId": "c2036693-b954-4014-d057-ab79b5192d8a"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  gender   age  hypertension  heart_disease ever_married  \\\n",
              "0      9046    Male  67.0             0              1          Yes   \n",
              "1     51676  Female  61.0             0              0          Yes   \n",
              "2     31112    Male  80.0             0              1          Yes   \n",
              "3     60182  Female  49.0             0              0          Yes   \n",
              "4      1665  Female  79.0             1              0          Yes   \n",
              "...     ...     ...   ...           ...            ...          ...   \n",
              "5105  18234  Female  80.0             1              0          Yes   \n",
              "5106  44873  Female  81.0             0              0          Yes   \n",
              "5107  19723  Female  35.0             0              0          Yes   \n",
              "5108  37544    Male  51.0             0              0          Yes   \n",
              "5109  44679  Female  44.0             0              0          Yes   \n",
              "\n",
              "          work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
              "0           Private          Urban             228.69  36.6  formerly smoked   \n",
              "1     Self-employed          Rural             202.21   NaN     never smoked   \n",
              "2           Private          Rural             105.92  32.5     never smoked   \n",
              "3           Private          Urban             171.23  34.4           smokes   \n",
              "4     Self-employed          Rural             174.12  24.0     never smoked   \n",
              "...             ...            ...                ...   ...              ...   \n",
              "5105        Private          Urban              83.75   NaN     never smoked   \n",
              "5106  Self-employed          Urban             125.20  40.0     never smoked   \n",
              "5107  Self-employed          Rural              82.99  30.6     never smoked   \n",
              "5108        Private          Rural             166.29  25.6  formerly smoked   \n",
              "5109       Govt_job          Urban              85.28  26.2          Unknown   \n",
              "\n",
              "      stroke  \n",
              "0          1  \n",
              "1          1  \n",
              "2          1  \n",
              "3          1  \n",
              "4          1  \n",
              "...      ...  \n",
              "5105       0  \n",
              "5106       0  \n",
              "5107       0  \n",
              "5108       0  \n",
              "5109       0  \n",
              "\n",
              "[5110 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f85d5d8-6958-4ce3-afb0-60bd87c2a5d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9046</td>\n",
              "      <td>Male</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51676</td>\n",
              "      <td>Female</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>202.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31112</td>\n",
              "      <td>Male</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60182</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>smokes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1665</td>\n",
              "      <td>Female</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5105</th>\n",
              "      <td>18234</td>\n",
              "      <td>Female</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>83.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>44873</td>\n",
              "      <td>Female</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Urban</td>\n",
              "      <td>125.20</td>\n",
              "      <td>40.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5107</th>\n",
              "      <td>19723</td>\n",
              "      <td>Female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>82.99</td>\n",
              "      <td>30.6</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>37544</td>\n",
              "      <td>Male</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>166.29</td>\n",
              "      <td>25.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5109</th>\n",
              "      <td>44679</td>\n",
              "      <td>Female</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Govt_job</td>\n",
              "      <td>Urban</td>\n",
              "      <td>85.28</td>\n",
              "      <td>26.2</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5110 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f85d5d8-6958-4ce3-afb0-60bd87c2a5d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f85d5d8-6958-4ce3-afb0-60bd87c2a5d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f85d5d8-6958-4ce3-afb0-60bd87c2a5d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['bmi'].isna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o1qtnjSF13J",
        "outputId": "f2e12052-b7c1-43d2-b1d1-e2c932b0e82f"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       False\n",
              "1        True\n",
              "2       False\n",
              "3       False\n",
              "4       False\n",
              "        ...  \n",
              "5105     True\n",
              "5106    False\n",
              "5107    False\n",
              "5108    False\n",
              "5109    False\n",
              "Name: bmi, Length: 5110, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['bmi'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFy_dbr_F6kh",
        "outputId": "3dbc3684-5c5c-47f0-9752-6263a14ec9c6"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.7    41\n",
              "28.4    38\n",
              "26.7    37\n",
              "27.6    37\n",
              "26.1    37\n",
              "        ..\n",
              "48.7     1\n",
              "49.2     1\n",
              "51.0     1\n",
              "49.4     1\n",
              "14.9     1\n",
              "Name: bmi, Length: 418, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df['bmi'].fillna(np.random)"
      ],
      "metadata": {
        "id": "d_v-5hXAGBBx"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df['bmi'].isna()==False]"
      ],
      "metadata": {
        "id": "Dru_j3k4HEKh"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "YgM4nrkIHLBZ",
        "outputId": "5edc9dcf-a1cc-498a-9682-ac07137b88ea"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  gender   age  hypertension  heart_disease ever_married  \\\n",
              "0      9046    Male  67.0             0              1          Yes   \n",
              "2     31112    Male  80.0             0              1          Yes   \n",
              "3     60182  Female  49.0             0              0          Yes   \n",
              "4      1665  Female  79.0             1              0          Yes   \n",
              "5     56669    Male  81.0             0              0          Yes   \n",
              "...     ...     ...   ...           ...            ...          ...   \n",
              "5104  14180  Female  13.0             0              0           No   \n",
              "5106  44873  Female  81.0             0              0          Yes   \n",
              "5107  19723  Female  35.0             0              0          Yes   \n",
              "5108  37544    Male  51.0             0              0          Yes   \n",
              "5109  44679  Female  44.0             0              0          Yes   \n",
              "\n",
              "          work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
              "0           Private          Urban             228.69  36.6  formerly smoked   \n",
              "2           Private          Rural             105.92  32.5     never smoked   \n",
              "3           Private          Urban             171.23  34.4           smokes   \n",
              "4     Self-employed          Rural             174.12  24.0     never smoked   \n",
              "5           Private          Urban             186.21  29.0  formerly smoked   \n",
              "...             ...            ...                ...   ...              ...   \n",
              "5104       children          Rural             103.08  18.6          Unknown   \n",
              "5106  Self-employed          Urban             125.20  40.0     never smoked   \n",
              "5107  Self-employed          Rural              82.99  30.6     never smoked   \n",
              "5108        Private          Rural             166.29  25.6  formerly smoked   \n",
              "5109       Govt_job          Urban              85.28  26.2          Unknown   \n",
              "\n",
              "      stroke  \n",
              "0          1  \n",
              "2          1  \n",
              "3          1  \n",
              "4          1  \n",
              "5          1  \n",
              "...      ...  \n",
              "5104       0  \n",
              "5106       0  \n",
              "5107       0  \n",
              "5108       0  \n",
              "5109       0  \n",
              "\n",
              "[4909 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76ee9b88-6b99-4f80-9ecb-5cb740b3d621\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9046</td>\n",
              "      <td>Male</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31112</td>\n",
              "      <td>Male</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60182</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>smokes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1665</td>\n",
              "      <td>Female</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>56669</td>\n",
              "      <td>Male</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>186.21</td>\n",
              "      <td>29.0</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5104</th>\n",
              "      <td>14180</td>\n",
              "      <td>Female</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>children</td>\n",
              "      <td>Rural</td>\n",
              "      <td>103.08</td>\n",
              "      <td>18.6</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>44873</td>\n",
              "      <td>Female</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Urban</td>\n",
              "      <td>125.20</td>\n",
              "      <td>40.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5107</th>\n",
              "      <td>19723</td>\n",
              "      <td>Female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>82.99</td>\n",
              "      <td>30.6</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>37544</td>\n",
              "      <td>Male</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>166.29</td>\n",
              "      <td>25.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5109</th>\n",
              "      <td>44679</td>\n",
              "      <td>Female</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Govt_job</td>\n",
              "      <td>Urban</td>\n",
              "      <td>85.28</td>\n",
              "      <td>26.2</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4909 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76ee9b88-6b99-4f80-9ecb-5cb740b3d621')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76ee9b88-6b99-4f80-9ecb-5cb740b3d621 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76ee9b88-6b99-4f80-9ecb-5cb740b3d621');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Residence_type'].value_counts())\n",
        "print(df['smoking_status'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V1bdMTXHTNJ",
        "outputId": "cf216398-9d53-4ff3-d550-f31ef1f14afa"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Urban    2490\n",
            "Rural    2419\n",
            "Name: Residence_type, dtype: int64\n",
            "never smoked       1852\n",
            "Unknown            1483\n",
            "formerly smoked     837\n",
            "smokes              737\n",
            "Name: smoking_status, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "df['gender']=le.fit_transform(df['gender'])#Male=1 Female=0\n",
        "df['Residence_type']=le.fit_transform(df['Residence_type'])#Urban=1 Rural=0\n",
        "df['ever_married']=le.fit_transform(df['ever_married'])#Urban=1 Rural=0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HAMGJVFH6N5",
        "outputId": "eb1f3000-2e0c-466c-ee1e-af5fb69ce7bf"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-208-1f57809f45d8>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['gender']=le.fit_transform(df['gender'])#Male=1 Female=0\n",
            "<ipython-input-208-1f57809f45d8>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Residence_type']=le.fit_transform(df['Residence_type'])#Urban=1 Rural=0\n",
            "<ipython-input-208-1f57809f45d8>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['ever_married']=le.fit_transform(df['ever_married'])#Urban=1 Rural=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "sk_cwe1VIp3x",
        "outputId": "9360a36e-ad4c-47a4-cd90-cd79c0c32672"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  gender   age  hypertension  heart_disease  ever_married  \\\n",
              "0      9046       1  67.0             0              1             1   \n",
              "2     31112       1  80.0             0              1             1   \n",
              "3     60182       0  49.0             0              0             1   \n",
              "4      1665       0  79.0             1              0             1   \n",
              "5     56669       1  81.0             0              0             1   \n",
              "...     ...     ...   ...           ...            ...           ...   \n",
              "5104  14180       0  13.0             0              0             0   \n",
              "5106  44873       0  81.0             0              0             1   \n",
              "5107  19723       0  35.0             0              0             1   \n",
              "5108  37544       1  51.0             0              0             1   \n",
              "5109  44679       0  44.0             0              0             1   \n",
              "\n",
              "          work_type  Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
              "0           Private               1             228.69  36.6  formerly smoked   \n",
              "2           Private               0             105.92  32.5     never smoked   \n",
              "3           Private               1             171.23  34.4           smokes   \n",
              "4     Self-employed               0             174.12  24.0     never smoked   \n",
              "5           Private               1             186.21  29.0  formerly smoked   \n",
              "...             ...             ...                ...   ...              ...   \n",
              "5104       children               0             103.08  18.6          Unknown   \n",
              "5106  Self-employed               1             125.20  40.0     never smoked   \n",
              "5107  Self-employed               0              82.99  30.6     never smoked   \n",
              "5108        Private               0             166.29  25.6  formerly smoked   \n",
              "5109       Govt_job               1              85.28  26.2          Unknown   \n",
              "\n",
              "      stroke  \n",
              "0          1  \n",
              "2          1  \n",
              "3          1  \n",
              "4          1  \n",
              "5          1  \n",
              "...      ...  \n",
              "5104       0  \n",
              "5106       0  \n",
              "5107       0  \n",
              "5108       0  \n",
              "5109       0  \n",
              "\n",
              "[4909 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a96c6a8-ed8d-4f72-9919-41aa26cf21c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9046</td>\n",
              "      <td>1</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Private</td>\n",
              "      <td>1</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31112</td>\n",
              "      <td>1</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Private</td>\n",
              "      <td>0</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60182</td>\n",
              "      <td>0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Private</td>\n",
              "      <td>1</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>smokes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1665</td>\n",
              "      <td>0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>0</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>56669</td>\n",
              "      <td>1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Private</td>\n",
              "      <td>1</td>\n",
              "      <td>186.21</td>\n",
              "      <td>29.0</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5104</th>\n",
              "      <td>14180</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>children</td>\n",
              "      <td>0</td>\n",
              "      <td>103.08</td>\n",
              "      <td>18.6</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>44873</td>\n",
              "      <td>0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>1</td>\n",
              "      <td>125.20</td>\n",
              "      <td>40.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5107</th>\n",
              "      <td>19723</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>0</td>\n",
              "      <td>82.99</td>\n",
              "      <td>30.6</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>37544</td>\n",
              "      <td>1</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Private</td>\n",
              "      <td>0</td>\n",
              "      <td>166.29</td>\n",
              "      <td>25.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5109</th>\n",
              "      <td>44679</td>\n",
              "      <td>0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Govt_job</td>\n",
              "      <td>1</td>\n",
              "      <td>85.28</td>\n",
              "      <td>26.2</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4909 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a96c6a8-ed8d-4f72-9919-41aa26cf21c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a96c6a8-ed8d-4f72-9919-41aa26cf21c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a96c6a8-ed8d-4f72-9919-41aa26cf21c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.get_dummies(df,columns=['work_type','smoking_status'])"
      ],
      "metadata": {
        "id": "D54GiiPCJSK5"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPrRmrxGJ8ho",
        "outputId": "fae88ef1-5d19-4ea9-93ed-d34336587c28"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n",
              "       'Residence_type', 'avg_glucose_level', 'bmi', 'stroke',\n",
              "       'work_type_Govt_job', 'work_type_Never_worked', 'work_type_Private',\n",
              "       'work_type_Self-employed', 'work_type_children',\n",
              "       'smoking_status_Unknown', 'smoking_status_formerly smoked',\n",
              "       'smoking_status_never smoked', 'smoking_status_smokes'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "30H5KvRZKT9Z",
        "outputId": "76668742-6073-4919-c6aa-0acf57820f6e"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id  gender   age  hypertension  heart_disease  ever_married  \\\n",
              "0   9046       1  67.0             0              1             1   \n",
              "2  31112       1  80.0             0              1             1   \n",
              "3  60182       0  49.0             0              0             1   \n",
              "4   1665       0  79.0             1              0             1   \n",
              "5  56669       1  81.0             0              0             1   \n",
              "\n",
              "   Residence_type  avg_glucose_level   bmi  stroke  work_type_Govt_job  \\\n",
              "0               1             228.69  36.6       1                   0   \n",
              "2               0             105.92  32.5       1                   0   \n",
              "3               1             171.23  34.4       1                   0   \n",
              "4               0             174.12  24.0       1                   0   \n",
              "5               1             186.21  29.0       1                   0   \n",
              "\n",
              "   work_type_Never_worked  work_type_Private  work_type_Self-employed  \\\n",
              "0                       0                  1                        0   \n",
              "2                       0                  1                        0   \n",
              "3                       0                  1                        0   \n",
              "4                       0                  0                        1   \n",
              "5                       0                  1                        0   \n",
              "\n",
              "   work_type_children  smoking_status_Unknown  smoking_status_formerly smoked  \\\n",
              "0                   0                       0                               1   \n",
              "2                   0                       0                               0   \n",
              "3                   0                       0                               0   \n",
              "4                   0                       0                               0   \n",
              "5                   0                       0                               1   \n",
              "\n",
              "   smoking_status_never smoked  smoking_status_smokes  \n",
              "0                            0                      0  \n",
              "2                            1                      0  \n",
              "3                            0                      1  \n",
              "4                            1                      0  \n",
              "5                            0                      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd5545e1-9d34-4a60-b4ac-c8ac0cf378cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>stroke</th>\n",
              "      <th>work_type_Govt_job</th>\n",
              "      <th>work_type_Never_worked</th>\n",
              "      <th>work_type_Private</th>\n",
              "      <th>work_type_Self-employed</th>\n",
              "      <th>work_type_children</th>\n",
              "      <th>smoking_status_Unknown</th>\n",
              "      <th>smoking_status_formerly smoked</th>\n",
              "      <th>smoking_status_never smoked</th>\n",
              "      <th>smoking_status_smokes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9046</td>\n",
              "      <td>1</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31112</td>\n",
              "      <td>1</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60182</td>\n",
              "      <td>0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1665</td>\n",
              "      <td>0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>56669</td>\n",
              "      <td>1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>186.21</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd5545e1-9d34-4a60-b4ac-c8ac0cf378cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd5545e1-9d34-4a60-b4ac-c8ac0cf378cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd5545e1-9d34-4a60-b4ac-c8ac0cf378cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler()"
      ],
      "metadata": {
        "id": "FepkC8xEK2hH"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['avg_glucose_level','bmi','age']]=scaler.fit_transform(df[['avg_glucose_level','bmi','age']])"
      ],
      "metadata": {
        "id": "8pGuMVwJNAV3"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('id',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "NkEd4nDbRQLn"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train Test Splits for Autoencoder"
      ],
      "metadata": {
        "id": "h6VWpYHxNX6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "LABEL='stroke'\n",
        "features=df.drop(LABEL,axis=1)\n",
        "label=df[LABEL]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    features, label, test_size=0.2,shuffle=True,stratify=label\n",
        ")\n"
      ],
      "metadata": {
        "id": "8oO6yucHNx_Q"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "b507tcAwQ-4W",
        "outputId": "08c864c5-33fd-4ee9-cba2-9574751291f4"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      gender       age  hypertension  heart_disease  ever_married  \\\n",
              "2762       0  0.206543             0              0             0   \n",
              "950        1  0.182129             0              0             0   \n",
              "2658       0  0.743652             0              0             1   \n",
              "537        1  0.792480             0              0             1   \n",
              "4303       1  0.017090             0              0             0   \n",
              "...      ...       ...           ...            ...           ...   \n",
              "4222       0  0.414062             0              0             1   \n",
              "2790       1  0.121094             0              0             0   \n",
              "3416       0  0.572754             0              0             1   \n",
              "669        1  0.487305             0              0             1   \n",
              "3002       1  0.731445             0              0             1   \n",
              "\n",
              "      Residence_type  avg_glucose_level       bmi  work_type_Govt_job  \\\n",
              "2762               0           0.203905  0.124857                   0   \n",
              "950                1           0.013018  0.359679                   0   \n",
              "2658               1           0.234928  0.271478                   1   \n",
              "537                1           0.233081  0.201604                   0   \n",
              "4303               0           0.262672  0.121420                   0   \n",
              "...              ...                ...       ...                 ...   \n",
              "4222               0           0.146801  0.134021                   0   \n",
              "2790               0           0.063798  0.088202                   0   \n",
              "3416               1           0.105207  0.229095                   0   \n",
              "669                0           0.208383  0.179840                   1   \n",
              "3002               0           0.046348  0.234822                   0   \n",
              "\n",
              "      work_type_Never_worked  work_type_Private  work_type_Self-employed  \\\n",
              "2762                       0                  1                        0   \n",
              "950                        0                  1                        0   \n",
              "2658                       0                  0                        0   \n",
              "537                        0                  0                        1   \n",
              "4303                       0                  0                        0   \n",
              "...                      ...                ...                      ...   \n",
              "4222                       0                  1                        0   \n",
              "2790                       0                  0                        0   \n",
              "3416                       0                  1                        0   \n",
              "669                        0                  0                        0   \n",
              "3002                       0                  1                        0   \n",
              "\n",
              "      work_type_children  smoking_status_Unknown  \\\n",
              "2762                   0                       1   \n",
              "950                    0                       1   \n",
              "2658                   0                       0   \n",
              "537                    0                       1   \n",
              "4303                   1                       1   \n",
              "...                  ...                     ...   \n",
              "4222                   0                       1   \n",
              "2790                   1                       1   \n",
              "3416                   0                       0   \n",
              "669                    0                       1   \n",
              "3002                   0                       0   \n",
              "\n",
              "      smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
              "2762                               0                            0   \n",
              "950                                0                            0   \n",
              "2658                               0                            0   \n",
              "537                                0                            0   \n",
              "4303                               0                            0   \n",
              "...                              ...                          ...   \n",
              "4222                               0                            0   \n",
              "2790                               0                            0   \n",
              "3416                               1                            0   \n",
              "669                                0                            0   \n",
              "3002                               0                            1   \n",
              "\n",
              "      smoking_status_smokes  \n",
              "2762                      0  \n",
              "950                       0  \n",
              "2658                      1  \n",
              "537                       0  \n",
              "4303                      0  \n",
              "...                     ...  \n",
              "4222                      0  \n",
              "2790                      0  \n",
              "3416                      0  \n",
              "669                       0  \n",
              "3002                      0  \n",
              "\n",
              "[3927 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ea105da-46a7-4b62-a633-d12df4bd7a73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>work_type_Govt_job</th>\n",
              "      <th>work_type_Never_worked</th>\n",
              "      <th>work_type_Private</th>\n",
              "      <th>work_type_Self-employed</th>\n",
              "      <th>work_type_children</th>\n",
              "      <th>smoking_status_Unknown</th>\n",
              "      <th>smoking_status_formerly smoked</th>\n",
              "      <th>smoking_status_never smoked</th>\n",
              "      <th>smoking_status_smokes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2762</th>\n",
              "      <td>0</td>\n",
              "      <td>0.206543</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.203905</td>\n",
              "      <td>0.124857</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>950</th>\n",
              "      <td>1</td>\n",
              "      <td>0.182129</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.013018</td>\n",
              "      <td>0.359679</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2658</th>\n",
              "      <td>0</td>\n",
              "      <td>0.743652</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.234928</td>\n",
              "      <td>0.271478</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>1</td>\n",
              "      <td>0.792480</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.233081</td>\n",
              "      <td>0.201604</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4303</th>\n",
              "      <td>1</td>\n",
              "      <td>0.017090</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.262672</td>\n",
              "      <td>0.121420</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4222</th>\n",
              "      <td>0</td>\n",
              "      <td>0.414062</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.146801</td>\n",
              "      <td>0.134021</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2790</th>\n",
              "      <td>1</td>\n",
              "      <td>0.121094</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.063798</td>\n",
              "      <td>0.088202</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3416</th>\n",
              "      <td>0</td>\n",
              "      <td>0.572754</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.105207</td>\n",
              "      <td>0.229095</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>1</td>\n",
              "      <td>0.487305</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.208383</td>\n",
              "      <td>0.179840</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3002</th>\n",
              "      <td>1</td>\n",
              "      <td>0.731445</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046348</td>\n",
              "      <td>0.234822</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3927 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ea105da-46a7-4b62-a633-d12df4bd7a73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ea105da-46a7-4b62-a633-d12df4bd7a73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ea105da-46a7-4b62-a633-d12df4bd7a73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#0 for no stroke(normal) 1 for stroke(anomaly)\n",
        "train_index=y_train[y_train==0].index\n",
        "train_data=x_train.loc[train_index]"
      ],
      "metadata": {
        "id": "hav-JyN_Obg3"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.losses import MeanSquaredLogarithmicError"
      ],
      "metadata": {
        "id": "JOwjfsWkPm0e"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(Model):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  output_units: int\n",
        "    Number of output units\n",
        "  \n",
        "  code_size: int\n",
        "    Number of units in bottle neck\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, output_units, code_size=8):\n",
        "    super().__init__()\n",
        "    self.encoder = Sequential([\n",
        "      Dense(64, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(16, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(code_size, activation='relu')\n",
        "    ])\n",
        "    self.decoder = Sequential([\n",
        "      Dense(16, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(64, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(output_units, activation='sigmoid')\n",
        "    ])\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    encoded = self.encoder(inputs)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ],
      "metadata": {
        "id": "tuauLGl6PMHn"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoEncoder(output_units=train_data.shape[1])\n",
        "# configurations of model\n",
        "model.compile(loss='msle', metrics=['mse'], optimizer='adam')\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    train_data,\n",
        "    epochs=500,\n",
        "    batch_size=512,\n",
        "    validation_data=(x_test, x_test)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZr6DbYRPO_f",
        "outputId": "110d3bd9-be97-4ca7-e0a3-8736c01f7ac8"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 1s 42ms/step - loss: 0.1254 - mse: 0.2200 - val_loss: 0.1220 - val_mse: 0.2147\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1186 - mse: 0.2085 - val_loss: 0.1114 - val_mse: 0.1972\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1044 - mse: 0.1860 - val_loss: 0.0916 - val_mse: 0.1681\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0845 - mse: 0.1594 - val_loss: 0.0731 - val_mse: 0.1469\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0734 - mse: 0.1493 - val_loss: 0.0703 - val_mse: 0.1478\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0716 - mse: 0.1486 - val_loss: 0.0684 - val_mse: 0.1439\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0694 - mse: 0.1437 - val_loss: 0.0665 - val_mse: 0.1387\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0679 - mse: 0.1395 - val_loss: 0.0657 - val_mse: 0.1368\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0673 - mse: 0.1387 - val_loss: 0.0647 - val_mse: 0.1357\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0662 - mse: 0.1376 - val_loss: 0.0639 - val_mse: 0.1348\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0658 - mse: 0.1368 - val_loss: 0.0630 - val_mse: 0.1327\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0649 - mse: 0.1352 - val_loss: 0.0618 - val_mse: 0.1301\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0634 - mse: 0.1322 - val_loss: 0.0603 - val_mse: 0.1268\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0623 - mse: 0.1295 - val_loss: 0.0584 - val_mse: 0.1229\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0605 - mse: 0.1263 - val_loss: 0.0561 - val_mse: 0.1186\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0585 - mse: 0.1224 - val_loss: 0.0534 - val_mse: 0.1132\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0559 - mse: 0.1174 - val_loss: 0.0502 - val_mse: 0.1064\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0533 - mse: 0.1119 - val_loss: 0.0470 - val_mse: 0.0996\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0504 - mse: 0.1060 - val_loss: 0.0446 - val_mse: 0.0948\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0486 - mse: 0.1021 - val_loss: 0.0436 - val_mse: 0.0919\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0473 - mse: 0.0989 - val_loss: 0.0426 - val_mse: 0.0899\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0462 - mse: 0.0970 - val_loss: 0.0419 - val_mse: 0.0886\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0455 - mse: 0.0952 - val_loss: 0.0413 - val_mse: 0.0868\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0446 - mse: 0.0933 - val_loss: 0.0404 - val_mse: 0.0852\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0442 - mse: 0.0928 - val_loss: 0.0398 - val_mse: 0.0839\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0434 - mse: 0.0909 - val_loss: 0.0390 - val_mse: 0.0821\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0427 - mse: 0.0896 - val_loss: 0.0382 - val_mse: 0.0804\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0419 - mse: 0.0880 - val_loss: 0.0372 - val_mse: 0.0786\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0411 - mse: 0.0862 - val_loss: 0.0363 - val_mse: 0.0765\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0398 - mse: 0.0839 - val_loss: 0.0351 - val_mse: 0.0745\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0391 - mse: 0.0824 - val_loss: 0.0343 - val_mse: 0.0726\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0384 - mse: 0.0811 - val_loss: 0.0335 - val_mse: 0.0711\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0374 - mse: 0.0789 - val_loss: 0.0329 - val_mse: 0.0695\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0370 - mse: 0.0779 - val_loss: 0.0324 - val_mse: 0.0687\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0364 - mse: 0.0768 - val_loss: 0.0320 - val_mse: 0.0681\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0357 - mse: 0.0756 - val_loss: 0.0316 - val_mse: 0.0673\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0354 - mse: 0.0749 - val_loss: 0.0312 - val_mse: 0.0665\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0349 - mse: 0.0739 - val_loss: 0.0308 - val_mse: 0.0658\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0347 - mse: 0.0734 - val_loss: 0.0304 - val_mse: 0.0647\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0343 - mse: 0.0726 - val_loss: 0.0301 - val_mse: 0.0639\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0337 - mse: 0.0715 - val_loss: 0.0295 - val_mse: 0.0631\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0336 - mse: 0.0713 - val_loss: 0.0292 - val_mse: 0.0619\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0331 - mse: 0.0701 - val_loss: 0.0286 - val_mse: 0.0612\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0329 - mse: 0.0699 - val_loss: 0.0283 - val_mse: 0.0604\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0326 - mse: 0.0692 - val_loss: 0.0279 - val_mse: 0.0594\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0319 - mse: 0.0675 - val_loss: 0.0276 - val_mse: 0.0589\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0318 - mse: 0.0676 - val_loss: 0.0273 - val_mse: 0.0583\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0314 - mse: 0.0667 - val_loss: 0.0270 - val_mse: 0.0577\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0311 - mse: 0.0660 - val_loss: 0.0267 - val_mse: 0.0570\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0309 - mse: 0.0657 - val_loss: 0.0265 - val_mse: 0.0570\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0308 - mse: 0.0657 - val_loss: 0.0263 - val_mse: 0.0563\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0304 - mse: 0.0644 - val_loss: 0.0261 - val_mse: 0.0557\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0303 - mse: 0.0645 - val_loss: 0.0259 - val_mse: 0.0555\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0302 - mse: 0.0640 - val_loss: 0.0258 - val_mse: 0.0553\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0299 - mse: 0.0637 - val_loss: 0.0256 - val_mse: 0.0549\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0295 - mse: 0.0628 - val_loss: 0.0256 - val_mse: 0.0544\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0295 - mse: 0.0625 - val_loss: 0.0253 - val_mse: 0.0545\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0295 - mse: 0.0628 - val_loss: 0.0253 - val_mse: 0.0541\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0291 - mse: 0.0621 - val_loss: 0.0252 - val_mse: 0.0541\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0291 - mse: 0.0621 - val_loss: 0.0251 - val_mse: 0.0537\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0287 - mse: 0.0609 - val_loss: 0.0249 - val_mse: 0.0534\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0286 - mse: 0.0609 - val_loss: 0.0247 - val_mse: 0.0531\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0285 - mse: 0.0607 - val_loss: 0.0247 - val_mse: 0.0527\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0284 - mse: 0.0606 - val_loss: 0.0243 - val_mse: 0.0525\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0280 - mse: 0.0597 - val_loss: 0.0243 - val_mse: 0.0519\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0280 - mse: 0.0595 - val_loss: 0.0240 - val_mse: 0.0517\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0278 - mse: 0.0593 - val_loss: 0.0239 - val_mse: 0.0512\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0275 - mse: 0.0587 - val_loss: 0.0237 - val_mse: 0.0509\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0274 - mse: 0.0586 - val_loss: 0.0235 - val_mse: 0.0505\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0272 - mse: 0.0578 - val_loss: 0.0232 - val_mse: 0.0501\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0270 - mse: 0.0577 - val_loss: 0.0231 - val_mse: 0.0496\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0268 - mse: 0.0570 - val_loss: 0.0228 - val_mse: 0.0492\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0267 - mse: 0.0570 - val_loss: 0.0227 - val_mse: 0.0487\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0266 - mse: 0.0567 - val_loss: 0.0224 - val_mse: 0.0483\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0265 - mse: 0.0567 - val_loss: 0.0223 - val_mse: 0.0477\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0260 - mse: 0.0554 - val_loss: 0.0220 - val_mse: 0.0475\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0259 - mse: 0.0552 - val_loss: 0.0218 - val_mse: 0.0467\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0256 - mse: 0.0547 - val_loss: 0.0215 - val_mse: 0.0465\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0255 - mse: 0.0545 - val_loss: 0.0213 - val_mse: 0.0457\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0254 - mse: 0.0540 - val_loss: 0.0209 - val_mse: 0.0454\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0249 - mse: 0.0533 - val_loss: 0.0208 - val_mse: 0.0448\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0248 - mse: 0.0530 - val_loss: 0.0206 - val_mse: 0.0444\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0249 - mse: 0.0530 - val_loss: 0.0202 - val_mse: 0.0437\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0247 - mse: 0.0526 - val_loss: 0.0202 - val_mse: 0.0435\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0245 - mse: 0.0525 - val_loss: 0.0199 - val_mse: 0.0428\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0246 - mse: 0.0524 - val_loss: 0.0198 - val_mse: 0.0423\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0243 - mse: 0.0518 - val_loss: 0.0195 - val_mse: 0.0423\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0240 - mse: 0.0514 - val_loss: 0.0193 - val_mse: 0.0415\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0240 - mse: 0.0510 - val_loss: 0.0191 - val_mse: 0.0412\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0236 - mse: 0.0504 - val_loss: 0.0188 - val_mse: 0.0406\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0234 - mse: 0.0497 - val_loss: 0.0187 - val_mse: 0.0401\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0232 - mse: 0.0495 - val_loss: 0.0184 - val_mse: 0.0398\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0234 - mse: 0.0499 - val_loss: 0.0182 - val_mse: 0.0392\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0229 - mse: 0.0488 - val_loss: 0.0179 - val_mse: 0.0386\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0231 - mse: 0.0491 - val_loss: 0.0180 - val_mse: 0.0388\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0230 - mse: 0.0490 - val_loss: 0.0176 - val_mse: 0.0381\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0228 - mse: 0.0485 - val_loss: 0.0175 - val_mse: 0.0378\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0224 - mse: 0.0477 - val_loss: 0.0172 - val_mse: 0.0373\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0221 - mse: 0.0472 - val_loss: 0.0171 - val_mse: 0.0365\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0220 - mse: 0.0469 - val_loss: 0.0169 - val_mse: 0.0366\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0222 - mse: 0.0475 - val_loss: 0.0166 - val_mse: 0.0360\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0218 - mse: 0.0463 - val_loss: 0.0165 - val_mse: 0.0356\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0218 - mse: 0.0466 - val_loss: 0.0163 - val_mse: 0.0354\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0218 - mse: 0.0464 - val_loss: 0.0161 - val_mse: 0.0347\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0215 - mse: 0.0457 - val_loss: 0.0159 - val_mse: 0.0345\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0216 - mse: 0.0460 - val_loss: 0.0160 - val_mse: 0.0343\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0212 - mse: 0.0451 - val_loss: 0.0157 - val_mse: 0.0339\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0209 - mse: 0.0443 - val_loss: 0.0156 - val_mse: 0.0337\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0207 - mse: 0.0442 - val_loss: 0.0154 - val_mse: 0.0330\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0206 - mse: 0.0438 - val_loss: 0.0153 - val_mse: 0.0331\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0209 - mse: 0.0444 - val_loss: 0.0151 - val_mse: 0.0324\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0204 - mse: 0.0432 - val_loss: 0.0149 - val_mse: 0.0322\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0205 - mse: 0.0438 - val_loss: 0.0149 - val_mse: 0.0321\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0204 - mse: 0.0434 - val_loss: 0.0146 - val_mse: 0.0317\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0202 - mse: 0.0432 - val_loss: 0.0146 - val_mse: 0.0313\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0201 - mse: 0.0427 - val_loss: 0.0145 - val_mse: 0.0314\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0202 - mse: 0.0432 - val_loss: 0.0144 - val_mse: 0.0311\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0200 - mse: 0.0425 - val_loss: 0.0143 - val_mse: 0.0306\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0196 - mse: 0.0418 - val_loss: 0.0143 - val_mse: 0.0308\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0195 - mse: 0.0414 - val_loss: 0.0141 - val_mse: 0.0303\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0195 - mse: 0.0415 - val_loss: 0.0140 - val_mse: 0.0301\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0192 - mse: 0.0409 - val_loss: 0.0139 - val_mse: 0.0297\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0196 - mse: 0.0415 - val_loss: 0.0138 - val_mse: 0.0296\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0191 - mse: 0.0407 - val_loss: 0.0137 - val_mse: 0.0294\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0193 - mse: 0.0409 - val_loss: 0.0135 - val_mse: 0.0291\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0192 - mse: 0.0409 - val_loss: 0.0136 - val_mse: 0.0290\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0190 - mse: 0.0404 - val_loss: 0.0135 - val_mse: 0.0289\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0191 - mse: 0.0406 - val_loss: 0.0134 - val_mse: 0.0287\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0186 - mse: 0.0395 - val_loss: 0.0133 - val_mse: 0.0284\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0188 - mse: 0.0399 - val_loss: 0.0133 - val_mse: 0.0286\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0187 - mse: 0.0397 - val_loss: 0.0132 - val_mse: 0.0282\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0186 - mse: 0.0394 - val_loss: 0.0130 - val_mse: 0.0280\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0187 - mse: 0.0397 - val_loss: 0.0130 - val_mse: 0.0278\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0185 - mse: 0.0393 - val_loss: 0.0128 - val_mse: 0.0275\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0183 - mse: 0.0388 - val_loss: 0.0128 - val_mse: 0.0275\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0183 - mse: 0.0389 - val_loss: 0.0128 - val_mse: 0.0272\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0178 - mse: 0.0377 - val_loss: 0.0127 - val_mse: 0.0272\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0181 - mse: 0.0383 - val_loss: 0.0126 - val_mse: 0.0269\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0179 - mse: 0.0380 - val_loss: 0.0125 - val_mse: 0.0267\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0180 - mse: 0.0383 - val_loss: 0.0126 - val_mse: 0.0267\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0180 - mse: 0.0382 - val_loss: 0.0124 - val_mse: 0.0266\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0180 - mse: 0.0382 - val_loss: 0.0124 - val_mse: 0.0266\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0177 - mse: 0.0375 - val_loss: 0.0123 - val_mse: 0.0263\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0177 - mse: 0.0375 - val_loss: 0.0122 - val_mse: 0.0261\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0176 - mse: 0.0372 - val_loss: 0.0122 - val_mse: 0.0262\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0175 - mse: 0.0373 - val_loss: 0.0122 - val_mse: 0.0260\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0177 - mse: 0.0374 - val_loss: 0.0121 - val_mse: 0.0257\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0172 - mse: 0.0365 - val_loss: 0.0121 - val_mse: 0.0258\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0178 - mse: 0.0375 - val_loss: 0.0120 - val_mse: 0.0256\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0173 - mse: 0.0368 - val_loss: 0.0119 - val_mse: 0.0254\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0173 - mse: 0.0366 - val_loss: 0.0119 - val_mse: 0.0253\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0171 - mse: 0.0363 - val_loss: 0.0118 - val_mse: 0.0251\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0170 - mse: 0.0358 - val_loss: 0.0118 - val_mse: 0.0250\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0173 - mse: 0.0366 - val_loss: 0.0118 - val_mse: 0.0251\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0170 - mse: 0.0360 - val_loss: 0.0118 - val_mse: 0.0249\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0170 - mse: 0.0359 - val_loss: 0.0117 - val_mse: 0.0248\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0171 - mse: 0.0363 - val_loss: 0.0116 - val_mse: 0.0247\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0169 - mse: 0.0358 - val_loss: 0.0117 - val_mse: 0.0248\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0169 - mse: 0.0358 - val_loss: 0.0116 - val_mse: 0.0248\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0170 - mse: 0.0360 - val_loss: 0.0115 - val_mse: 0.0245\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0168 - mse: 0.0355 - val_loss: 0.0114 - val_mse: 0.0243\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0168 - mse: 0.0355 - val_loss: 0.0114 - val_mse: 0.0244\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0165 - mse: 0.0350 - val_loss: 0.0114 - val_mse: 0.0242\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0166 - mse: 0.0351 - val_loss: 0.0114 - val_mse: 0.0242\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0164 - mse: 0.0347 - val_loss: 0.0114 - val_mse: 0.0243\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0165 - mse: 0.0349 - val_loss: 0.0113 - val_mse: 0.0241\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0163 - mse: 0.0345 - val_loss: 0.0113 - val_mse: 0.0240\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0164 - mse: 0.0346 - val_loss: 0.0113 - val_mse: 0.0239\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0164 - mse: 0.0347 - val_loss: 0.0112 - val_mse: 0.0238\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0162 - mse: 0.0342 - val_loss: 0.0112 - val_mse: 0.0237\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0162 - mse: 0.0343 - val_loss: 0.0112 - val_mse: 0.0238\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0162 - mse: 0.0343 - val_loss: 0.0112 - val_mse: 0.0238\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0160 - mse: 0.0339 - val_loss: 0.0112 - val_mse: 0.0236\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0163 - mse: 0.0344 - val_loss: 0.0111 - val_mse: 0.0236\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0163 - mse: 0.0346 - val_loss: 0.0111 - val_mse: 0.0234\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0160 - mse: 0.0337 - val_loss: 0.0111 - val_mse: 0.0234\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0161 - mse: 0.0342 - val_loss: 0.0110 - val_mse: 0.0235\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0160 - mse: 0.0336 - val_loss: 0.0110 - val_mse: 0.0232\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0160 - mse: 0.0339 - val_loss: 0.0110 - val_mse: 0.0233\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0163 - mse: 0.0342 - val_loss: 0.0110 - val_mse: 0.0232\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0159 - mse: 0.0335 - val_loss: 0.0109 - val_mse: 0.0231\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0157 - mse: 0.0332 - val_loss: 0.0109 - val_mse: 0.0232\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0159 - mse: 0.0338 - val_loss: 0.0109 - val_mse: 0.0229\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0158 - mse: 0.0333 - val_loss: 0.0109 - val_mse: 0.0229\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0155 - mse: 0.0326 - val_loss: 0.0109 - val_mse: 0.0231\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0159 - mse: 0.0337 - val_loss: 0.0108 - val_mse: 0.0229\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0156 - mse: 0.0330 - val_loss: 0.0108 - val_mse: 0.0229\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0159 - mse: 0.0336 - val_loss: 0.0108 - val_mse: 0.0227\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0155 - mse: 0.0326 - val_loss: 0.0108 - val_mse: 0.0227\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0155 - mse: 0.0327 - val_loss: 0.0107 - val_mse: 0.0226\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0155 - mse: 0.0327 - val_loss: 0.0107 - val_mse: 0.0224\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0157 - mse: 0.0330 - val_loss: 0.0106 - val_mse: 0.0226\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0153 - mse: 0.0324 - val_loss: 0.0106 - val_mse: 0.0224\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0153 - mse: 0.0323 - val_loss: 0.0106 - val_mse: 0.0224\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0155 - mse: 0.0327 - val_loss: 0.0106 - val_mse: 0.0225\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0155 - mse: 0.0327 - val_loss: 0.0106 - val_mse: 0.0225\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0151 - mse: 0.0319 - val_loss: 0.0107 - val_mse: 0.0224\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0153 - mse: 0.0321 - val_loss: 0.0106 - val_mse: 0.0223\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0152 - mse: 0.0321 - val_loss: 0.0105 - val_mse: 0.0223\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0152 - mse: 0.0321 - val_loss: 0.0105 - val_mse: 0.0221\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0152 - mse: 0.0320 - val_loss: 0.0105 - val_mse: 0.0222\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0154 - mse: 0.0324 - val_loss: 0.0105 - val_mse: 0.0224\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0150 - mse: 0.0317 - val_loss: 0.0105 - val_mse: 0.0220\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0153 - mse: 0.0322 - val_loss: 0.0104 - val_mse: 0.0220\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0151 - mse: 0.0320 - val_loss: 0.0104 - val_mse: 0.0219\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0149 - mse: 0.0314 - val_loss: 0.0104 - val_mse: 0.0218\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0152 - mse: 0.0320 - val_loss: 0.0104 - val_mse: 0.0219\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0152 - mse: 0.0320 - val_loss: 0.0104 - val_mse: 0.0219\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0148 - mse: 0.0313 - val_loss: 0.0104 - val_mse: 0.0219\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0148 - mse: 0.0313 - val_loss: 0.0103 - val_mse: 0.0217\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0149 - mse: 0.0314 - val_loss: 0.0103 - val_mse: 0.0217\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0148 - mse: 0.0313 - val_loss: 0.0103 - val_mse: 0.0217\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0148 - mse: 0.0312 - val_loss: 0.0103 - val_mse: 0.0217\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0148 - mse: 0.0312 - val_loss: 0.0102 - val_mse: 0.0217\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0147 - mse: 0.0312 - val_loss: 0.0103 - val_mse: 0.0217\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0147 - mse: 0.0311 - val_loss: 0.0102 - val_mse: 0.0216\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0146 - mse: 0.0308 - val_loss: 0.0102 - val_mse: 0.0214\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0150 - mse: 0.0315 - val_loss: 0.0103 - val_mse: 0.0216\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0147 - mse: 0.0311 - val_loss: 0.0102 - val_mse: 0.0214\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0149 - mse: 0.0313 - val_loss: 0.0102 - val_mse: 0.0215\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0147 - mse: 0.0311 - val_loss: 0.0102 - val_mse: 0.0215\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0147 - mse: 0.0310 - val_loss: 0.0101 - val_mse: 0.0213\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0145 - mse: 0.0305 - val_loss: 0.0101 - val_mse: 0.0213\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0145 - mse: 0.0305 - val_loss: 0.0100 - val_mse: 0.0212\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0148 - mse: 0.0313 - val_loss: 0.0101 - val_mse: 0.0212\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0146 - mse: 0.0308 - val_loss: 0.0101 - val_mse: 0.0213\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0148 - mse: 0.0313 - val_loss: 0.0101 - val_mse: 0.0214\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0146 - mse: 0.0307 - val_loss: 0.0100 - val_mse: 0.0211\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0143 - mse: 0.0300 - val_loss: 0.0100 - val_mse: 0.0211\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0144 - mse: 0.0303 - val_loss: 0.0100 - val_mse: 0.0211\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0143 - mse: 0.0302 - val_loss: 0.0099 - val_mse: 0.0209\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0145 - mse: 0.0305 - val_loss: 0.0100 - val_mse: 0.0210\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0148 - mse: 0.0312 - val_loss: 0.0099 - val_mse: 0.0209\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0142 - mse: 0.0298 - val_loss: 0.0099 - val_mse: 0.0207\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0144 - mse: 0.0303 - val_loss: 0.0099 - val_mse: 0.0208\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0145 - mse: 0.0308 - val_loss: 0.0099 - val_mse: 0.0208\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0143 - mse: 0.0300 - val_loss: 0.0099 - val_mse: 0.0207\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0144 - mse: 0.0303 - val_loss: 0.0099 - val_mse: 0.0209\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0146 - mse: 0.0308 - val_loss: 0.0099 - val_mse: 0.0208\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0144 - mse: 0.0301 - val_loss: 0.0098 - val_mse: 0.0207\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0145 - mse: 0.0305 - val_loss: 0.0098 - val_mse: 0.0206\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0141 - mse: 0.0296 - val_loss: 0.0098 - val_mse: 0.0206\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0142 - mse: 0.0300 - val_loss: 0.0098 - val_mse: 0.0207\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0143 - mse: 0.0301 - val_loss: 0.0098 - val_mse: 0.0207\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0143 - mse: 0.0300 - val_loss: 0.0098 - val_mse: 0.0207\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0141 - mse: 0.0298 - val_loss: 0.0098 - val_mse: 0.0206\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0141 - mse: 0.0296 - val_loss: 0.0097 - val_mse: 0.0205\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0140 - mse: 0.0294 - val_loss: 0.0097 - val_mse: 0.0204\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0141 - mse: 0.0298 - val_loss: 0.0097 - val_mse: 0.0204\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0139 - mse: 0.0291 - val_loss: 0.0097 - val_mse: 0.0203\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0141 - mse: 0.0296 - val_loss: 0.0096 - val_mse: 0.0203\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0139 - mse: 0.0292 - val_loss: 0.0096 - val_mse: 0.0204\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0138 - mse: 0.0291 - val_loss: 0.0097 - val_mse: 0.0203\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0141 - mse: 0.0296 - val_loss: 0.0096 - val_mse: 0.0202\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0139 - mse: 0.0292 - val_loss: 0.0095 - val_mse: 0.0202\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0139 - mse: 0.0292 - val_loss: 0.0095 - val_mse: 0.0200\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0141 - mse: 0.0295 - val_loss: 0.0096 - val_mse: 0.0202\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0140 - mse: 0.0295 - val_loss: 0.0096 - val_mse: 0.0204\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0141 - mse: 0.0297 - val_loss: 0.0096 - val_mse: 0.0201\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0140 - mse: 0.0292 - val_loss: 0.0095 - val_mse: 0.0201\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0138 - mse: 0.0291 - val_loss: 0.0095 - val_mse: 0.0201\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0138 - mse: 0.0290 - val_loss: 0.0095 - val_mse: 0.0200\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0137 - mse: 0.0288 - val_loss: 0.0095 - val_mse: 0.0199\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0137 - mse: 0.0288 - val_loss: 0.0095 - val_mse: 0.0201\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0139 - mse: 0.0295 - val_loss: 0.0095 - val_mse: 0.0200\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0138 - mse: 0.0290 - val_loss: 0.0095 - val_mse: 0.0200\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0135 - mse: 0.0285 - val_loss: 0.0095 - val_mse: 0.0200\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0137 - mse: 0.0289 - val_loss: 0.0095 - val_mse: 0.0200\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0138 - mse: 0.0290 - val_loss: 0.0095 - val_mse: 0.0200\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0137 - mse: 0.0289 - val_loss: 0.0095 - val_mse: 0.0199\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0135 - mse: 0.0284 - val_loss: 0.0095 - val_mse: 0.0198\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0138 - mse: 0.0289 - val_loss: 0.0094 - val_mse: 0.0198\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0134 - mse: 0.0281 - val_loss: 0.0094 - val_mse: 0.0198\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0140 - mse: 0.0293 - val_loss: 0.0094 - val_mse: 0.0198\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0135 - mse: 0.0283 - val_loss: 0.0094 - val_mse: 0.0199\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0138 - mse: 0.0290 - val_loss: 0.0094 - val_mse: 0.0197\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0137 - mse: 0.0287 - val_loss: 0.0094 - val_mse: 0.0198\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0135 - mse: 0.0285 - val_loss: 0.0095 - val_mse: 0.0200\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0138 - mse: 0.0291 - val_loss: 0.0094 - val_mse: 0.0198\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0133 - mse: 0.0279 - val_loss: 0.0094 - val_mse: 0.0198\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0136 - mse: 0.0286 - val_loss: 0.0094 - val_mse: 0.0198\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0138 - mse: 0.0291 - val_loss: 0.0094 - val_mse: 0.0197\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0136 - mse: 0.0284 - val_loss: 0.0094 - val_mse: 0.0198\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0134 - mse: 0.0283 - val_loss: 0.0093 - val_mse: 0.0197\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0136 - mse: 0.0284 - val_loss: 0.0093 - val_mse: 0.0195\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0136 - mse: 0.0284 - val_loss: 0.0093 - val_mse: 0.0195\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0132 - mse: 0.0279 - val_loss: 0.0092 - val_mse: 0.0195\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0135 - mse: 0.0285 - val_loss: 0.0093 - val_mse: 0.0195\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0134 - mse: 0.0280 - val_loss: 0.0093 - val_mse: 0.0195\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0136 - mse: 0.0284 - val_loss: 0.0093 - val_mse: 0.0195\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0134 - mse: 0.0282 - val_loss: 0.0093 - val_mse: 0.0195\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0135 - mse: 0.0284 - val_loss: 0.0093 - val_mse: 0.0195\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0133 - mse: 0.0280 - val_loss: 0.0093 - val_mse: 0.0195\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0134 - mse: 0.0282 - val_loss: 0.0093 - val_mse: 0.0195\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0134 - mse: 0.0280 - val_loss: 0.0092 - val_mse: 0.0195\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0132 - mse: 0.0278 - val_loss: 0.0092 - val_mse: 0.0194\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0133 - mse: 0.0278 - val_loss: 0.0093 - val_mse: 0.0194\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0131 - mse: 0.0274 - val_loss: 0.0092 - val_mse: 0.0194\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0132 - mse: 0.0279 - val_loss: 0.0092 - val_mse: 0.0193\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0130 - mse: 0.0274 - val_loss: 0.0092 - val_mse: 0.0193\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0133 - mse: 0.0280 - val_loss: 0.0092 - val_mse: 0.0193\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0133 - mse: 0.0277 - val_loss: 0.0092 - val_mse: 0.0192\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0134 - mse: 0.0281 - val_loss: 0.0092 - val_mse: 0.0194\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0133 - mse: 0.0280 - val_loss: 0.0092 - val_mse: 0.0193\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0133 - mse: 0.0280 - val_loss: 0.0091 - val_mse: 0.0192\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0132 - mse: 0.0278 - val_loss: 0.0091 - val_mse: 0.0191\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0134 - mse: 0.0280 - val_loss: 0.0091 - val_mse: 0.0191\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0134 - mse: 0.0280 - val_loss: 0.0091 - val_mse: 0.0192\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0133 - mse: 0.0280 - val_loss: 0.0091 - val_mse: 0.0192\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0131 - mse: 0.0276 - val_loss: 0.0091 - val_mse: 0.0191\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0131 - mse: 0.0274 - val_loss: 0.0091 - val_mse: 0.0191\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0132 - mse: 0.0276 - val_loss: 0.0091 - val_mse: 0.0192\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0127 - mse: 0.0268 - val_loss: 0.0091 - val_mse: 0.0191\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0132 - mse: 0.0276 - val_loss: 0.0091 - val_mse: 0.0191\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0132 - mse: 0.0277 - val_loss: 0.0091 - val_mse: 0.0190\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0135 - mse: 0.0285 - val_loss: 0.0092 - val_mse: 0.0191\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0129 - mse: 0.0271 - val_loss: 0.0091 - val_mse: 0.0190\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0133 - mse: 0.0280 - val_loss: 0.0090 - val_mse: 0.0190\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0127 - mse: 0.0266 - val_loss: 0.0090 - val_mse: 0.0189\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0125 - mse: 0.0262 - val_loss: 0.0090 - val_mse: 0.0189\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0131 - mse: 0.0275 - val_loss: 0.0090 - val_mse: 0.0190\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0131 - mse: 0.0275 - val_loss: 0.0090 - val_mse: 0.0188\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0129 - mse: 0.0270 - val_loss: 0.0090 - val_mse: 0.0189\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0129 - mse: 0.0270 - val_loss: 0.0090 - val_mse: 0.0189\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0128 - mse: 0.0269 - val_loss: 0.0090 - val_mse: 0.0188\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0126 - mse: 0.0264 - val_loss: 0.0090 - val_mse: 0.0188\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0129 - mse: 0.0270 - val_loss: 0.0089 - val_mse: 0.0188\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0127 - mse: 0.0267 - val_loss: 0.0089 - val_mse: 0.0188\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0130 - mse: 0.0272 - val_loss: 0.0089 - val_mse: 0.0187\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0132 - mse: 0.0276 - val_loss: 0.0089 - val_mse: 0.0188\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0128 - mse: 0.0268 - val_loss: 0.0089 - val_mse: 0.0187\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0129 - mse: 0.0271 - val_loss: 0.0089 - val_mse: 0.0187\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0130 - mse: 0.0273 - val_loss: 0.0089 - val_mse: 0.0187\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0130 - mse: 0.0273 - val_loss: 0.0089 - val_mse: 0.0188\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0126 - mse: 0.0266 - val_loss: 0.0089 - val_mse: 0.0188\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0127 - mse: 0.0267 - val_loss: 0.0089 - val_mse: 0.0187\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0129 - mse: 0.0270 - val_loss: 0.0089 - val_mse: 0.0186\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0126 - mse: 0.0265 - val_loss: 0.0089 - val_mse: 0.0187\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - mse: 0.0265 - val_loss: 0.0089 - val_mse: 0.0187\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0124 - mse: 0.0260 - val_loss: 0.0089 - val_mse: 0.0187\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0130 - mse: 0.0272 - val_loss: 0.0089 - val_mse: 0.0186\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0129 - mse: 0.0270 - val_loss: 0.0089 - val_mse: 0.0187\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - mse: 0.0264 - val_loss: 0.0089 - val_mse: 0.0187\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - mse: 0.0263 - val_loss: 0.0089 - val_mse: 0.0186\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0126 - mse: 0.0264 - val_loss: 0.0089 - val_mse: 0.0187\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0125 - mse: 0.0264 - val_loss: 0.0088 - val_mse: 0.0186\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0123 - mse: 0.0259 - val_loss: 0.0088 - val_mse: 0.0186\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0128 - mse: 0.0270 - val_loss: 0.0088 - val_mse: 0.0186\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0127 - mse: 0.0264 - val_loss: 0.0088 - val_mse: 0.0185\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - mse: 0.0266 - val_loss: 0.0088 - val_mse: 0.0185\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0130 - mse: 0.0272 - val_loss: 0.0088 - val_mse: 0.0186\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - mse: 0.0265 - val_loss: 0.0088 - val_mse: 0.0185\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0125 - mse: 0.0261 - val_loss: 0.0088 - val_mse: 0.0185\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0125 - mse: 0.0264 - val_loss: 0.0088 - val_mse: 0.0185\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0125 - mse: 0.0262 - val_loss: 0.0088 - val_mse: 0.0185\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0124 - mse: 0.0260 - val_loss: 0.0088 - val_mse: 0.0185\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0123 - mse: 0.0259 - val_loss: 0.0088 - val_mse: 0.0184\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0129 - mse: 0.0270 - val_loss: 0.0088 - val_mse: 0.0184\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0125 - mse: 0.0261 - val_loss: 0.0088 - val_mse: 0.0184\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0126 - mse: 0.0265 - val_loss: 0.0088 - val_mse: 0.0185\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0125 - mse: 0.0263 - val_loss: 0.0088 - val_mse: 0.0185\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0127 - mse: 0.0266 - val_loss: 0.0087 - val_mse: 0.0183\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0123 - mse: 0.0259 - val_loss: 0.0087 - val_mse: 0.0183\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0124 - mse: 0.0260 - val_loss: 0.0087 - val_mse: 0.0183\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0123 - mse: 0.0259 - val_loss: 0.0088 - val_mse: 0.0185\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0127 - mse: 0.0268 - val_loss: 0.0088 - val_mse: 0.0184\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0124 - mse: 0.0259 - val_loss: 0.0087 - val_mse: 0.0182\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0123 - mse: 0.0257 - val_loss: 0.0087 - val_mse: 0.0184\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0125 - mse: 0.0261 - val_loss: 0.0087 - val_mse: 0.0182\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0124 - mse: 0.0259 - val_loss: 0.0087 - val_mse: 0.0183\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0122 - mse: 0.0256 - val_loss: 0.0087 - val_mse: 0.0183\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0125 - mse: 0.0263 - val_loss: 0.0087 - val_mse: 0.0182\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0125 - mse: 0.0262 - val_loss: 0.0087 - val_mse: 0.0182\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0123 - mse: 0.0257 - val_loss: 0.0087 - val_mse: 0.0182\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0122 - mse: 0.0254 - val_loss: 0.0087 - val_mse: 0.0181\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0126 - mse: 0.0264 - val_loss: 0.0087 - val_mse: 0.0183\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0123 - mse: 0.0258 - val_loss: 0.0087 - val_mse: 0.0183\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0126 - mse: 0.0264 - val_loss: 0.0086 - val_mse: 0.0183\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0122 - mse: 0.0257 - val_loss: 0.0086 - val_mse: 0.0181\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0122 - mse: 0.0255 - val_loss: 0.0087 - val_mse: 0.0181\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0125 - mse: 0.0262 - val_loss: 0.0086 - val_mse: 0.0181\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0123 - mse: 0.0258 - val_loss: 0.0086 - val_mse: 0.0181\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0124 - mse: 0.0259 - val_loss: 0.0087 - val_mse: 0.0182\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0125 - mse: 0.0261 - val_loss: 0.0086 - val_mse: 0.0181\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0122 - mse: 0.0256 - val_loss: 0.0086 - val_mse: 0.0181\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0124 - mse: 0.0261 - val_loss: 0.0086 - val_mse: 0.0181\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0253 - val_loss: 0.0086 - val_mse: 0.0180\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0127 - mse: 0.0265 - val_loss: 0.0086 - val_mse: 0.0180\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0120 - mse: 0.0250 - val_loss: 0.0086 - val_mse: 0.0181\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0124 - mse: 0.0260 - val_loss: 0.0086 - val_mse: 0.0181\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0120 - mse: 0.0251 - val_loss: 0.0086 - val_mse: 0.0180\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0122 - mse: 0.0256 - val_loss: 0.0086 - val_mse: 0.0180\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0122 - mse: 0.0255 - val_loss: 0.0086 - val_mse: 0.0181\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0122 - mse: 0.0255 - val_loss: 0.0086 - val_mse: 0.0181\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0122 - mse: 0.0256 - val_loss: 0.0086 - val_mse: 0.0180\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0122 - mse: 0.0256 - val_loss: 0.0085 - val_mse: 0.0179\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0121 - mse: 0.0254 - val_loss: 0.0086 - val_mse: 0.0180\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0253 - val_loss: 0.0085 - val_mse: 0.0179\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0254 - val_loss: 0.0085 - val_mse: 0.0178\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0121 - mse: 0.0253 - val_loss: 0.0085 - val_mse: 0.0178\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0254 - val_loss: 0.0085 - val_mse: 0.0180\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0254 - val_loss: 0.0085 - val_mse: 0.0180\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0119 - mse: 0.0250 - val_loss: 0.0085 - val_mse: 0.0178\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0122 - mse: 0.0257 - val_loss: 0.0085 - val_mse: 0.0179\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0253 - val_loss: 0.0085 - val_mse: 0.0179\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0123 - mse: 0.0258 - val_loss: 0.0085 - val_mse: 0.0178\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0123 - mse: 0.0257 - val_loss: 0.0086 - val_mse: 0.0180\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0121 - mse: 0.0254 - val_loss: 0.0085 - val_mse: 0.0180\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0118 - mse: 0.0249 - val_loss: 0.0085 - val_mse: 0.0179\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0122 - mse: 0.0255 - val_loss: 0.0085 - val_mse: 0.0179\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0120 - mse: 0.0252 - val_loss: 0.0085 - val_mse: 0.0178\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0254 - val_loss: 0.0085 - val_mse: 0.0178\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0120 - mse: 0.0251 - val_loss: 0.0085 - val_mse: 0.0179\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0252 - val_loss: 0.0084 - val_mse: 0.0177\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - mse: 0.0244 - val_loss: 0.0084 - val_mse: 0.0178\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - mse: 0.0253 - val_loss: 0.0085 - val_mse: 0.0178\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0120 - mse: 0.0251 - val_loss: 0.0085 - val_mse: 0.0178\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0123 - mse: 0.0258 - val_loss: 0.0084 - val_mse: 0.0176\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0119 - mse: 0.0249 - val_loss: 0.0084 - val_mse: 0.0177\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0118 - mse: 0.0247 - val_loss: 0.0084 - val_mse: 0.0177\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0119 - mse: 0.0251 - val_loss: 0.0084 - val_mse: 0.0176\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0120 - mse: 0.0252 - val_loss: 0.0084 - val_mse: 0.0176\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - mse: 0.0250 - val_loss: 0.0085 - val_mse: 0.0178\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0121 - mse: 0.0254 - val_loss: 0.0084 - val_mse: 0.0178\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0121 - mse: 0.0254 - val_loss: 0.0084 - val_mse: 0.0178\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - mse: 0.0247 - val_loss: 0.0084 - val_mse: 0.0176\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0253 - val_loss: 0.0084 - val_mse: 0.0176\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0120 - mse: 0.0250 - val_loss: 0.0084 - val_mse: 0.0176\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0121 - mse: 0.0251 - val_loss: 0.0084 - val_mse: 0.0177\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0120 - mse: 0.0252 - val_loss: 0.0084 - val_mse: 0.0176\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0117 - mse: 0.0247 - val_loss: 0.0084 - val_mse: 0.0176\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - mse: 0.0247 - val_loss: 0.0084 - val_mse: 0.0176\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - mse: 0.0247 - val_loss: 0.0084 - val_mse: 0.0175\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0116 - mse: 0.0244 - val_loss: 0.0083 - val_mse: 0.0176\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0119 - mse: 0.0250 - val_loss: 0.0083 - val_mse: 0.0175\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0254 - val_loss: 0.0083 - val_mse: 0.0175\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - mse: 0.0251 - val_loss: 0.0083 - val_mse: 0.0175\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0117 - mse: 0.0246 - val_loss: 0.0083 - val_mse: 0.0175\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0118 - mse: 0.0247 - val_loss: 0.0083 - val_mse: 0.0175\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0120 - mse: 0.0252 - val_loss: 0.0083 - val_mse: 0.0176\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - mse: 0.0251 - val_loss: 0.0083 - val_mse: 0.0176\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0116 - mse: 0.0245 - val_loss: 0.0083 - val_mse: 0.0174\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0119 - mse: 0.0249 - val_loss: 0.0083 - val_mse: 0.0173\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0119 - mse: 0.0250 - val_loss: 0.0083 - val_mse: 0.0174\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - mse: 0.0246 - val_loss: 0.0083 - val_mse: 0.0174\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0118 - mse: 0.0246 - val_loss: 0.0083 - val_mse: 0.0175\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - mse: 0.0245 - val_loss: 0.0083 - val_mse: 0.0175\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0117 - mse: 0.0245 - val_loss: 0.0083 - val_mse: 0.0175\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0118 - mse: 0.0247 - val_loss: 0.0083 - val_mse: 0.0174\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0114 - mse: 0.0239 - val_loss: 0.0083 - val_mse: 0.0174\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0117 - mse: 0.0245 - val_loss: 0.0082 - val_mse: 0.0173\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0117 - mse: 0.0245 - val_loss: 0.0082 - val_mse: 0.0173\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0120 - mse: 0.0252 - val_loss: 0.0083 - val_mse: 0.0173\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0116 - mse: 0.0242 - val_loss: 0.0082 - val_mse: 0.0173\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0119 - mse: 0.0249 - val_loss: 0.0082 - val_mse: 0.0173\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0115 - mse: 0.0242 - val_loss: 0.0082 - val_mse: 0.0172\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0119 - mse: 0.0249 - val_loss: 0.0082 - val_mse: 0.0173\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0117 - mse: 0.0244 - val_loss: 0.0082 - val_mse: 0.0172\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0116 - mse: 0.0243 - val_loss: 0.0082 - val_mse: 0.0174\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0118 - mse: 0.0248 - val_loss: 0.0082 - val_mse: 0.0173\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0115 - mse: 0.0241 - val_loss: 0.0082 - val_mse: 0.0172\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0115 - mse: 0.0240 - val_loss: 0.0081 - val_mse: 0.0171\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0115 - mse: 0.0241 - val_loss: 0.0081 - val_mse: 0.0171\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0111 - mse: 0.0232 - val_loss: 0.0081 - val_mse: 0.0171\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0115 - mse: 0.0241 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0116 - mse: 0.0243 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0115 - mse: 0.0241 - val_loss: 0.0081 - val_mse: 0.0171\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0115 - mse: 0.0242 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0114 - mse: 0.0239 - val_loss: 0.0081 - val_mse: 0.0169\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0115 - mse: 0.0241 - val_loss: 0.0081 - val_mse: 0.0171\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0115 - mse: 0.0241 - val_loss: 0.0081 - val_mse: 0.0171\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0119 - mse: 0.0249 - val_loss: 0.0081 - val_mse: 0.0169\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0113 - mse: 0.0236 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0114 - mse: 0.0239 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0115 - mse: 0.0241 - val_loss: 0.0081 - val_mse: 0.0171\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0115 - mse: 0.0240 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0114 - mse: 0.0238 - val_loss: 0.0081 - val_mse: 0.0171\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0115 - mse: 0.0241 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0114 - mse: 0.0240 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0115 - mse: 0.0241 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0115 - mse: 0.0241 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0117 - mse: 0.0244 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0116 - mse: 0.0242 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0113 - mse: 0.0236 - val_loss: 0.0081 - val_mse: 0.0172\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0113 - mse: 0.0237 - val_loss: 0.0081 - val_mse: 0.0172\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0114 - mse: 0.0239 - val_loss: 0.0081 - val_mse: 0.0171\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0113 - mse: 0.0237 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0116 - mse: 0.0244 - val_loss: 0.0081 - val_mse: 0.0171\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0115 - mse: 0.0241 - val_loss: 0.0081 - val_mse: 0.0169\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0116 - mse: 0.0242 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0115 - mse: 0.0241 - val_loss: 0.0081 - val_mse: 0.0169\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0113 - mse: 0.0237 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0114 - mse: 0.0238 - val_loss: 0.0081 - val_mse: 0.0170\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0112 - mse: 0.0236 - val_loss: 0.0080 - val_mse: 0.0168\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0116 - mse: 0.0242 - val_loss: 0.0081 - val_mse: 0.0169\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0114 - mse: 0.0240 - val_loss: 0.0080 - val_mse: 0.0169\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0115 - mse: 0.0240 - val_loss: 0.0080 - val_mse: 0.0168\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0114 - mse: 0.0238 - val_loss: 0.0080 - val_mse: 0.0168\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0112 - mse: 0.0233 - val_loss: 0.0080 - val_mse: 0.0169\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0115 - mse: 0.0240 - val_loss: 0.0080 - val_mse: 0.0169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSLE Loss')\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "M76bYZmiSNz2",
        "outputId": "4f24c1b1-6c82-4c5f-bb2f-c4a108b00cf0"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_threshold(model,train_data):\n",
        "  reconstructions = model.predict(train_data)\n",
        "  # provides losses of individual instances\n",
        "  reconstruction_errors = tf.keras.losses.msle(reconstructions, train_data)\n",
        "\n",
        "  # threshold for anomaly scores\n",
        "  threshold = np.mean(reconstruction_errors.numpy()) \\\n",
        "      + np.std(reconstruction_errors.numpy())\n",
        "  return threshold\n",
        "\n",
        "def find_threshold_method_two(model, train_data):\n",
        "  # another method to find threshold\n",
        "  reconstructions = model.predict(train_data)\n",
        "  # provides losses of individual instances\n",
        "  reconstruction_errors = tf.keras.losses.msle(reconstructions, train_data)\n",
        "\n",
        "  threshold_2 = np.percentile(reconstruction_errors, 95)\n",
        "  return threshold_2\n",
        "\n",
        "def get_predictions(model, x_test, threshold):\n",
        "  predictions = model.predict(x_test)\n",
        "  # provides losses of individual instances\n",
        "  errors = tf.keras.losses.msle(predictions, x_test)\n",
        "  # 0 = no stroke(normal), 1 = stroke(anomaly)\n",
        "  anomaly_mask = pd.Series(errors) > threshold\n",
        "  preds = anomaly_mask.map(lambda x: 1.0 if x == True else 0.0)\n",
        "  return preds"
      ],
      "metadata": {
        "id": "xnPKmjX5SZG2"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold=find_threshold(model,train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QWx4Xk7S5hQ",
        "outputId": "c6b34d1b-4133-4011-abe8-2ad1da6b51fd"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "preds = get_predictions(model, x_test, threshold)\n",
        "accuracy_score(preds, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTRnrbWpTCXH",
        "outputId": "84da44b0-48df-4158-c5cd-9dc7831b8b80"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8411405295315683"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    }
  ]
}